{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,SubsetRandomSampler,Sampler\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import glob\n",
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "import random\n",
    "import PIL.ImageEnhance as ie\n",
    "import copy\n",
    "from torch.autograd import Variable\n",
    "import PIL.Image as im\n",
    "from math import floor\n",
    "from google.colab import files,drive\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "torch.cuda.manual_seed(1337)\n",
    "np.random.seed(1337)\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):     \n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.data_frame['Id'][idx])         \n",
    "        image = Image.open(img_name).convert('RGB')                               \n",
    "        label = np.array(self.data_frame['Category'][idx])                        \n",
    "        if self.transform:            \n",
    "            image = self.transform(image)                                         \n",
    "        sample = (image, label)        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):    \n",
    "    def __init__(self, num_class, alpha=None, gamma=2, balance_index=-1, smooth=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.smooth = smooth\n",
    "        self.size_average = size_average\n",
    "\n",
    "        if self.alpha is None:\n",
    "            self.alpha = torch.ones(self.num_class, 1)\n",
    "        elif isinstance(self.alpha, (list, np.ndarray)):\n",
    "            assert len(self.alpha) == self.num_class\n",
    "            self.alpha = torch.FloatTensor(alpha).view(self.num_class, 1)\n",
    "            self.alpha = self.alpha / self.alpha.sum()\n",
    "        elif isinstance(self.alpha, float):\n",
    "            alpha = torch.ones(self.num_class, 1)\n",
    "            alpha = alpha * (1 - self.alpha)\n",
    "            alpha[balance_index] = self.alpha\n",
    "            self.alpha = alpha\n",
    "        else:\n",
    "            raise TypeError('Not support alpha type')\n",
    "\n",
    "        if self.smooth is not None:\n",
    "            if self.smooth < 0 or self.smooth > 1.0:\n",
    "                raise ValueError('smooth value should be in [0,1]')\n",
    "\n",
    "    def forward(self, logit, target):\n",
    "              \n",
    "        # logit = F.softmax(input, dim=1)\n",
    "\n",
    "        if logit.dim() > 2:\n",
    "            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n",
    "            logit = logit.view(logit.size(0), logit.size(1), -1)\n",
    "            logit = logit.permute(0, 2, 1).contiguous()\n",
    "            logit = logit.view(-1, logit.size(-1))\n",
    "        target = target.view(-1, 1)\n",
    "\n",
    "        # N = input.size(0)\n",
    "        # alpha = torch.ones(N, self.num_class)\n",
    "        # alpha = alpha * (1 - self.alpha)\n",
    "        # alpha = alpha.scatter_(1, target.long(), self.alpha)\n",
    "        epsilon = 1e-10\n",
    "        alpha = self.alpha\n",
    "        #print(type(alpha),type(self.alpha))\n",
    "        \n",
    "\n",
    "        idx = target.cpu().long()\n",
    "\n",
    "        one_hot_key = torch.FloatTensor(target.size(0), self.num_class).zero_()\n",
    "        one_hot_key = one_hot_key.scatter_(1, idx, 1)\n",
    "        if one_hot_key.device != logit.device:\n",
    "            one_hot_key = one_hot_key.to(logit.device)\n",
    "\n",
    "        if self.smooth:\n",
    "            one_hot_key = torch.clamp(\n",
    "                one_hot_key, self.smooth/(self.num_class-1), 1.0 - self.smooth)\n",
    "        pt = (one_hot_key * logit).sum(1) + epsilon\n",
    "        logpt = pt.log()\n",
    "\n",
    "        gamma = self.gamma\n",
    "\n",
    "        alpha = alpha[idx]\n",
    "        alpha=alpha.to(device)\n",
    "        loss = -1 * alpha * torch.pow((1 - pt), gamma) * logpt\n",
    "\n",
    "        if self.size_average:\n",
    "            loss = loss.mean()\n",
    "        else:\n",
    "            loss = loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetSampler(Sampler):    \n",
    "    def __init__(self, indices):\n",
    "        self.num_samples = len(indices)\n",
    "        self.indices = indices\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "class Lighting(object):\n",
    "    def __init__(self, alphastd, eigval, eigvec):\n",
    "        self.alphastd = alphastd\n",
    "        self.eigval = eigval\n",
    "        self.eigvec = eigvec\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if self.alphastd == 0:\n",
    "            return img\n",
    "\n",
    "        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n",
    "        rgb = self.eigvec.type_as(img).clone()\\\n",
    "            .mul(alpha.view(1, 3).expand(3, 3))\\\n",
    "            .mul(self.eigval.view(1, 3).expand(3, 3))\\\n",
    "            .sum(1).squeeze()\n",
    "\n",
    "        return img.add(rgb.view(3, 1, 1).expand_as(img))\n",
    "\n",
    "\n",
    "class Grayscale(object):\n",
    "    def __call__(self, img):\n",
    "        gs = img.clone()\n",
    "        gs[0].mul_(0.299).add_(0.587, gs[1]).add_(0.114, gs[2])\n",
    "        gs[1].copy_(gs[0])\n",
    "        gs[2].copy_(gs[0])\n",
    "        return gs\n",
    "\n",
    "\n",
    "class Saturation(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        gs = Grayscale()(img)\n",
    "        alpha = random.uniform(0, self.var)\n",
    "        return img.lerp(gs, alpha)\n",
    "\n",
    "\n",
    "class Brightness(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        gs = img.new().resize_as_(img).zero_()\n",
    "        alpha = random.uniform(0, self.var)\n",
    "        return img.lerp(gs, alpha)\n",
    "\n",
    "\n",
    "class Contrast(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        gs = Grayscale()(img)\n",
    "        gs.fill_(gs.mean())\n",
    "        alpha = random.uniform(0, self.var)\n",
    "        return img.lerp(gs, alpha)\n",
    "\n",
    "\n",
    "class RandomOrder(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if self.transforms is None:\n",
    "            return img\n",
    "        order = torch.randperm(len(self.transforms))\n",
    "        for i in order:\n",
    "            img = self.transforms[i](img)\n",
    "        return img\n",
    "\n",
    "\n",
    "class ColorJitter(RandomOrder):\n",
    "    def __init__(self, brightness=0.4, contrast=0.4, saturation=0.4):\n",
    "        self.transforms = []\n",
    "        if brightness != 0:\n",
    "            self.transforms.append(Brightness(brightness))\n",
    "        if contrast != 0:\n",
    "            self.transforms.append(Contrast(contrast))\n",
    "        if saturation != 0:\n",
    "            self.transforms.append(Saturation(saturation))\n",
    "\n",
    "class RandomFlip(object):\n",
    "    def __call__(self, img):\n",
    "        dispatcher = {\n",
    "            0: img,\n",
    "            1: img,\n",
    "            2: img.transpose(im.FLIP_LEFT_RIGHT),\n",
    "            3: img.transpose(im.FLIP_TOP_BOTTOM)\n",
    "        }\n",
    "    \n",
    "        return dispatcher[random.randint(0,3)] #randint is inclusive\n",
    "\n",
    "class RandomRotate(object):\n",
    "    def __call__(self, img):\n",
    "        dispatcher = {\n",
    "            0: img,\n",
    "            1: img,\n",
    "            2: img,            \n",
    "            3: img.transpose(im.ROTATE_90),\n",
    "            4: img.transpose(im.ROTATE_180),\n",
    "            5: img.transpose(im.ROTATE_270)\n",
    "        }\n",
    "    \n",
    "        return dispatcher[random.randint(0,5)] #randint is inclusive\n",
    "    \n",
    "class PILColorBalance(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        alpha = random.uniform(1 - self.var, 1 + self.var)\n",
    "        return ie.Color(img).enhance(alpha)\n",
    "\n",
    "class PILContrast(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        alpha = random.uniform(1 - self.var, 1 + self.var)\n",
    "        return ie.Contrast(img).enhance(alpha)\n",
    "\n",
    "\n",
    "class PILBrightness(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        alpha = random.uniform(1 - self.var, 1 + self.var)\n",
    "        return ie.Brightness(img).enhance(alpha)\n",
    "\n",
    "class PILSharpness(object):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __call__(self, img):\n",
    "        alpha = random.uniform(1 - self.var, 1 + self.var)\n",
    "        return ie.Sharpness(img).enhance(alpha)\n",
    "    \n",
    "\n",
    "\n",
    "class PowerPIL(RandomOrder):\n",
    "    def __init__(self, rotate=True,\n",
    "                       flip=True,\n",
    "                       colorbalance=0.4,\n",
    "                       contrast=0.4,\n",
    "                       brightness=0.4,\n",
    "                       sharpness=0.4):\n",
    "        self.transforms = []\n",
    "        if rotate:\n",
    "            self.transforms.append(RandomRotate())\n",
    "        if flip:\n",
    "            self.transforms.append(RandomFlip())\n",
    "        if brightness != 0:\n",
    "            self.transforms.append(PILBrightness(brightness))\n",
    "        if contrast != 0:\n",
    "            self.transforms.append(PILContrast(contrast))\n",
    "        if colorbalance != 0:\n",
    "            self.transforms.append(PILColorBalance(colorbalance))\n",
    "        if sharpness != 0:\n",
    "            self.transforms.append(PILSharpness(sharpness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Function to split dataset into train and validation\n",
    "def train_valid_split(dataset, test_size = 0.30, shuffle = False, random_seed = 0):\n",
    "    length = dataset.__len__()\n",
    "    indices = list(range(1,length))\n",
    "    \n",
    "    if shuffle == True:\n",
    "        random.seed(random_seed)\n",
    "        random.shuffle(indices)\n",
    "    \n",
    "    if type(test_size) is float:\n",
    "        split = floor(test_size * length)\n",
    "    elif type(test_size) is int:\n",
    "        split = test_size\n",
    "    else:\n",
    "        raise ValueError('%s should be an int or a float' % str)\n",
    "    return indices[split:], indices[:split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate image statistics mean and standard deviation\n",
    "def calculate_img_stats_avg(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "    for imgs,_ in loader:\n",
    "        batch_samples = imgs.size(0)\n",
    "        imgs = imgs.view(batch_samples, imgs.size(1), -1)\n",
    "        mean += imgs.mean(2).sum(0)\n",
    "        std += imgs.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "    return mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_augmented = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        PowerPIL(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                     ])\n",
    "transform_raw = transforms.Compose([\n",
    "                     transforms.Resize((224,224)),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-16 16:52:39--  http://groups.csail.mit.edu/vision/LabelMe/NewImages/indoorCVPR_09.tar\n",
      "Resolving groups.csail.mit.edu (groups.csail.mit.edu)... 128.30.2.44\n",
      "Connecting to groups.csail.mit.edu (groups.csail.mit.edu)|128.30.2.44|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2592010240 (2.4G) [application/x-tar]\n",
      "Saving to: ‘indoorCVPR_09.tar’\n",
      " \n",
      "indoorCVPR_09.tar   100%[===================>]   2.41G  8.16MB/s    in 5m 01s  \n",
      " \n",
      "2019-11-16 16:57:40 (8.12 MB/s) - ‘indoorCVPR_09.tar’ saved [2592010240/2592010240] \n"
     ]
    }
   ],
   "source": [
    "!wget http://groups.csail.mit.edu/vision/LabelMe/NewImages/indoorCVPR_09.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzipping the Data-set\n",
    "!tar -xvf indoorCVPR_09.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the files, so that all images are in a common directory and creating a train.csv with the category numerically encoded\n",
    "!cd Images\n",
    "files=os.listdir()\n",
    "files.sort()\n",
    "labeldict={}\n",
    "count=0\n",
    "\n",
    "for file in files:\n",
    "    labeldict[file]=count\n",
    "    count+=1\n",
    "    \n",
    "from collections import defaultdict\n",
    "class_freq=defaultdict(int)\n",
    "csvlist=[]\n",
    "\n",
    "for file in files:\n",
    "    images=os.listdir(os.path.join(os.getcwd(),file))\n",
    "    count=1\n",
    "    for img in images:\n",
    "        an=img.split(\".\")        \n",
    "        newname=str(file)+\"_\"+str(count)+\".\"+str(an[-1])\n",
    "        os.rename(os.path.join(os.getcwd(),file,img),os.path.join(os.getcwd(),newname))\n",
    "        csvlist.append([labeldict[file],newname])\n",
    "        class_freq[file]+=1\n",
    "        count+=1\n",
    "        \n",
    "for file in files:\n",
    "    os.rmdir(file)\n",
    "\n",
    "df=pd.DataFrame(csvlist,columns=[\"Category\",\"Id\"])\n",
    "df.to_csv(\"Train.csv\")\n",
    "!mv Train.csv ../Train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating weight of each category\n",
    "from collections import defaultdict\n",
    "class_freq=defaultdict(int)\n",
    "freq=[]\n",
    "for ind,val in df.iterrows():\n",
    "    class_freq[int(val[\"Category\"])]+=1\n",
    "for ind,val in class_freq.items():\n",
    "    freq.append([ind,val])\n",
    "freq.sort()\n",
    "freq=[i[1] for i in freq]\n",
    "wt_per_class=[0.]*67\n",
    "N=float(sum(freq))\n",
    "for i in range(67):                                                   \n",
    "        wt_per_class[i] = N/float(freq[i])\n",
    "weight=[0]*len(df)\n",
    "for ind,val in df.iterrows():\n",
    "    cat=val[\"Category\"]\n",
    "    weight[ind]=wt_per_class[cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Train set and Validation set\n",
    "trainset = ImageDataset(csv_file = 'Train.csv', root_dir = './Images', transform=transform_augmented)\n",
    "valset   = ImageDataset(csv_file = 'Train.csv', root_dir = './Images', transform=transform_raw)\n",
    "accset   = ImageDataset(csv_file = 'Train.csv', root_dir = './Images', transform=transform_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, valid_idx = train_valid_split(trainset, 0.30)\n",
    "#train_sampler = torch.utils.data.WeightedRandomSampler(weight, len(train_idx))\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetSampler(valid_idx)\n",
    "train_loader = DataLoader(trainset,batch_size=50,sampler=train_sampler,num_workers=4)    \n",
    "valid_loader = DataLoader(valset,batch_size=200,sampler=valid_sampler,num_workers=4)\n",
    "acc_loader   = DataLoader(accset,batch_size=200,num_workers=4)\n",
    "#loader = DataLoader(calcset,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/WSL-Images/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
      "Downloading: \"https://download.pytorch.org/models/ig_resnext101_32x16-c6f796b0.pth\" to /root/.cache/torch/checkpoints/ig_resnext101_32x16-c6f796b0.pth\n",
      "100%|██████████| 777518664/777518664 [00:07<00:00, 110246826.32it/s]\n"
     ]
    }
   ],
   "source": [
    "#Getting the model architecture of the Resnext101_32x16d and the pre-trained weights on ImageNet\n",
    "model_ft = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x16d_wsl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying some layers and freezing the model \n",
    "avgpool = model_ft.avgpool\n",
    "l4 = model_ft.layer4\n",
    "l3 = model_ft.layer3\n",
    "\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model_ft.fc = nn.Sequential(nn.Dropout(p=0.5),nn.Linear(2048, 1024),nn.LeakyReLU(inplace=True),nn.Linear(1024,67),nn.Softmax(dim=1))\n",
    "#model_ft.layer4 = l4\n",
    "#model_ft.layer3 = l3\n",
    "#model_ft.avgpool = avgpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 4096, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(4096, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 4096, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(4096, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 4096, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "      (bn2): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(4096, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01, inplace)\n",
      "    (3): Linear(in_features=1024, out_features=67, bias=True)\n",
      "    (4): Softmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Sending the model to GPU\n",
    "model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5          [-1, 512, 56, 56]          32,768\n",
      "       BatchNorm2d-6          [-1, 512, 56, 56]           1,024\n",
      "              ReLU-7          [-1, 512, 56, 56]               0\n",
      "            Conv2d-8          [-1, 512, 56, 56]          73,728\n",
      "       BatchNorm2d-9          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-10          [-1, 512, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         131,072\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17          [-1, 512, 56, 56]         131,072\n",
      "      BatchNorm2d-18          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-19          [-1, 512, 56, 56]               0\n",
      "           Conv2d-20          [-1, 512, 56, 56]          73,728\n",
      "      BatchNorm2d-21          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-22          [-1, 512, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]         131,072\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27          [-1, 512, 56, 56]         131,072\n",
      "      BatchNorm2d-28          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-29          [-1, 512, 56, 56]               0\n",
      "           Conv2d-30          [-1, 512, 56, 56]          73,728\n",
      "      BatchNorm2d-31          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-32          [-1, 512, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]         131,072\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37         [-1, 1024, 56, 56]         262,144\n",
      "      BatchNorm2d-38         [-1, 1024, 56, 56]           2,048\n",
      "             ReLU-39         [-1, 1024, 56, 56]               0\n",
      "           Conv2d-40         [-1, 1024, 28, 28]         294,912\n",
      "      BatchNorm2d-41         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-42         [-1, 1024, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]         524,288\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49         [-1, 1024, 28, 28]         524,288\n",
      "      BatchNorm2d-50         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-51         [-1, 1024, 28, 28]               0\n",
      "           Conv2d-52         [-1, 1024, 28, 28]         294,912\n",
      "      BatchNorm2d-53         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-54         [-1, 1024, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]         524,288\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59         [-1, 1024, 28, 28]         524,288\n",
      "      BatchNorm2d-60         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-61         [-1, 1024, 28, 28]               0\n",
      "           Conv2d-62         [-1, 1024, 28, 28]         294,912\n",
      "      BatchNorm2d-63         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-64         [-1, 1024, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]         524,288\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69         [-1, 1024, 28, 28]         524,288\n",
      "      BatchNorm2d-70         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-71         [-1, 1024, 28, 28]               0\n",
      "           Conv2d-72         [-1, 1024, 28, 28]         294,912\n",
      "      BatchNorm2d-73         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-74         [-1, 1024, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]         524,288\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79         [-1, 2048, 28, 28]       1,048,576\n",
      "      BatchNorm2d-80         [-1, 2048, 28, 28]           4,096\n",
      "             ReLU-81         [-1, 2048, 28, 28]               0\n",
      "           Conv2d-82         [-1, 2048, 14, 14]       1,179,648\n",
      "      BatchNorm2d-83         [-1, 2048, 14, 14]           4,096\n",
      "             ReLU-84         [-1, 2048, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]       2,097,152\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91         [-1, 2048, 14, 14]       2,097,152\n",
      "      BatchNorm2d-92         [-1, 2048, 14, 14]           4,096\n",
      "             ReLU-93         [-1, 2048, 14, 14]               0\n",
      "           Conv2d-94         [-1, 2048, 14, 14]       1,179,648\n",
      "      BatchNorm2d-95         [-1, 2048, 14, 14]           4,096\n",
      "             ReLU-96         [-1, 2048, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]       2,097,152\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-102         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-103         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-104         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-105         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-106         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-112         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-113         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-114         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-115         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-116         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-122         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-123         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-124         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-125         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-126         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-132         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-133         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-134         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-135         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-136         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-142         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-143         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-144         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-145         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-146         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-147         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-149         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-150         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-151         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-152         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-153         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-154         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-155         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-156         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-157         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-159         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-160         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-161         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-162         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-163         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-164         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-165         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-166         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-167         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-169         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-170         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-171         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-172         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-173         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-174         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-175         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-176         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-177         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-179         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-180         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-181         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-182         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-183         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-184         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-185         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-186         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-187         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-189         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-190         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-191         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-192         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-193         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-194         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-195         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-196         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-197         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-199         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-200         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-201         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-202         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-203         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-204         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-205         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-206         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-207         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-209         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-210         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-211         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-212         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-213         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-214         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-215         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-216         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-217         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-219         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-220         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-221         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-222         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-223         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-224         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-225         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-226         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-227         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-229         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-230         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-231         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-232         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-233         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-234         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-235         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-236         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-237         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-239         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-240         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-241         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-242         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-243         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-244         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-245         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-246         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-247         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-249         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-250         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-251         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-252         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-253         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-254         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-255         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-256         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-257         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-259         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-260         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-261         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-262         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-263         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-264         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-265         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-266         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-267         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-269         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-270         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-271         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-272         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-273         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-274         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-275         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-276         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-277         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-279         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-280         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-281         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-282         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-283         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-284         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-285         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-286         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-287         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-289         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-290         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-291         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-292         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-293         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-294         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-295         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-296         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-297         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-299         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-300         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-301         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-302         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-303         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-304         [-1, 2048, 14, 14]       1,179,648\n",
      "     BatchNorm2d-305         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-306         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-307         [-1, 1024, 14, 14]       2,097,152\n",
      "     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-309         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-310         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-311         [-1, 4096, 14, 14]       4,194,304\n",
      "     BatchNorm2d-312         [-1, 4096, 14, 14]           8,192\n",
      "            ReLU-313         [-1, 4096, 14, 14]               0\n",
      "          Conv2d-314           [-1, 4096, 7, 7]       4,718,592\n",
      "     BatchNorm2d-315           [-1, 4096, 7, 7]           8,192\n",
      "            ReLU-316           [-1, 4096, 7, 7]               0\n",
      "          Conv2d-317           [-1, 2048, 7, 7]       8,388,608\n",
      "     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-321           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-322           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-323           [-1, 4096, 7, 7]       8,388,608\n",
      "     BatchNorm2d-324           [-1, 4096, 7, 7]           8,192\n",
      "            ReLU-325           [-1, 4096, 7, 7]               0\n",
      "          Conv2d-326           [-1, 4096, 7, 7]       4,718,592\n",
      "     BatchNorm2d-327           [-1, 4096, 7, 7]           8,192\n",
      "            ReLU-328           [-1, 4096, 7, 7]               0\n",
      "          Conv2d-329           [-1, 2048, 7, 7]       8,388,608\n",
      "     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-331           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-332           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-333           [-1, 4096, 7, 7]       8,388,608\n",
      "     BatchNorm2d-334           [-1, 4096, 7, 7]           8,192\n",
      "            ReLU-335           [-1, 4096, 7, 7]               0\n",
      "          Conv2d-336           [-1, 4096, 7, 7]       4,718,592\n",
      "     BatchNorm2d-337           [-1, 4096, 7, 7]           8,192\n",
      "            ReLU-338           [-1, 4096, 7, 7]               0\n",
      "          Conv2d-339           [-1, 2048, 7, 7]       8,388,608\n",
      "     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-341           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-342           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-343           [-1, 2048, 1, 1]               0\n",
      "         Dropout-344                 [-1, 2048]               0\n",
      "          Linear-345                 [-1, 1024]       2,098,176\n",
      "       LeakyReLU-346                 [-1, 1024]               0\n",
      "          Linear-347                   [-1, 67]          68,675\n",
      "         Softmax-348                   [-1, 67]               0\n",
      "================================================================\n",
      "Total params: 194,144,643\n",
      "Trainable params: 2,166,851\n",
      "Non-trainable params: 191,977,792\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 1229.64\n",
      "Params size (MB): 740.60\n",
      "Estimated Total Size (MB): 1970.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Checking Model Summary\n",
    "from torchsummary import summary\n",
    "summary(model_ft,input_size=(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = FocalLoss()\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=0.001,momentum=0.9)#,weight_decay=0.00005)\n",
    "\n",
    "best_acc=0.0\n",
    "best_model_wts = copy.deepcopy(model_ft.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Finished Training    -----\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs=0 # insert suitable number ( 20-30), also manually lower learning rate\n",
    "for epoch in range(num_epochs):    \n",
    "    print(\"Epoch  : \"+str(epoch))\n",
    "    print(\"-\"*10)\n",
    "    \n",
    "    #training loop\n",
    "    running_loss = 0.0\n",
    "    running_corrects=0\n",
    "    wrong=0\n",
    "    model_ft.train()\n",
    "    for inp,labels in train_loader:\n",
    "        inp=inp.to(device)\n",
    "        labels=labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model_ft(inp)            \n",
    "            loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()       \n",
    "    epoch_loss = running_loss / (len(train_loader)*1.0)\n",
    "    print('TRAINING SET   Loss: {}'.format(epoch_loss))\n",
    "    \n",
    "    # validation loop\n",
    "    if True:\n",
    "        correct=0\n",
    "        wrong=0\n",
    "        model_ft.eval()\n",
    "        for inp,labels in valid_loader:\n",
    "            inp=inp.to(device)\n",
    "            labels=labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                outputs = model_ft(inp)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            correct += torch.sum(preds == labels)\n",
    "            wrong += torch.sum(preds != labels)\n",
    "                \n",
    "        acc = (correct.float()) / ((correct+wrong).float())\n",
    "        print('VALIDATION SET Correct: {} Wrong {} Acc {}'.format(correct,wrong,acc))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_model_wts = copy.deepcopy(model_ft.state_dict())      \n",
    "                  \n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "model_ft.load_state_dict(best_model_wts)\n",
    "torch.save( model_ft.state_dict(), \"best_model_resnext_16d_2048_1024_dropout_0.5_c_wts.pkl\")\n",
    "print('------ Finished Training    -----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IncompatibleKeys(missing_keys=[], unexpected_keys=[])\n"
     ]
    }
   ],
   "source": [
    "model_ft.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.12.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.28.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.21.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2019.11.16)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-2ayU2W8YnVgvfHEukbpT9-HyrLF5vXt\n",
      "To: /content/best_model_resnext_16d_2048_1024_dropout_0.5_b.pkl\n",
      "778MB [00:04, 168MB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "!gdown https://drive.google.com/uc?id=1-2ayU2W8YnVgvfHEukbpT9-HyrLF5vXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IncompatibleKeys(missing_keys=[], unexpected_keys=[])\n"
     ]
    }
   ],
   "source": [
    "# Loadind the weights of the downloaded model\n",
    "model_ft_wts=torch.load(\"best_model_resnext_16d_2048_1024_dropout_0.5_b.pkl\")\n",
    "model_ft.load_state_dict(model_ft_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY SET   Correct: 11179 Wrong 4441 ACC 0.715685019206164 \n"
     ]
    }
   ],
   "source": [
    "#Checking Accuracy on Complete Data Set\n",
    "if True: \n",
    "        correct=0\n",
    "        wrong=0\n",
    "        model_ft.eval()\n",
    "        for inp,labels in acc_loader:\n",
    "            inp=inp.to(device)\n",
    "            labels=labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                outputs = model_ft(inp)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            correct += torch.sum(preds == labels)\n",
    "            wrong += torch.sum(preds != labels)\n",
    "              \n",
    "        acc = (correct.float()) / ((correct+wrong).float())\n",
    "        print('ACCURACY SET   Correct: {} Wrong {} ACC {} '.format(correct,wrong,acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py_data_anal]",
   "language": "python",
   "name": "conda-env-py_data_anal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
